{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzDtupVJSv4p",
        "outputId": "b5334522-1136-47b1-9f36-ba84eee27b9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded Real Frames: 10000\n",
            "Loaded Fake Frames: 9988\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "load_path = \"/content/drive/MyDrive/processed_faces_final/sampled_frames.pkl\"\n",
        "\n",
        "with open(load_path, \"rb\") as f:\n",
        "    data = pickle.load(f)\n",
        "\n",
        "real_sampled = data[\"real\"]\n",
        "fake_sampled = data[\"fake\"]\n",
        "\n",
        "print(f\"Loaded Real Frames: {len(real_sampled)}\")\n",
        "print(f\"Loaded Fake Frames: {len(fake_sampled)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "class DeepfakeDataset(Dataset):\n",
        "    def __init__(self, frame_paths, label, transform=None):\n",
        "        self.frame_paths = frame_paths\n",
        "        self.labels = [label] * len(frame_paths)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.frame_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.frame_paths[idx]\n",
        "\n",
        "        # Albumentations works with NumPy arrays (BGR format for OpenCV)\n",
        "        image = cv2.imread(img_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image=image)[\"image\"]  # Albumentations returns a dict\n",
        "\n",
        "        return image, self.labels[idx]\n"
      ],
      "metadata": {
        "id": "8IbWgsEfdiNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "\n",
        "def split_video_wise(frames, test_size=0.15, val_size=0.15):\n",
        "    # Extract video folder name from path\n",
        "    video_folders = list(set([os.path.dirname(p) for p in frames]))\n",
        "\n",
        "    train_videos, temp_videos = train_test_split(video_folders, test_size=(test_size + val_size), random_state=42)\n",
        "    val_videos, test_videos = train_test_split(temp_videos, test_size=(test_size/(test_size + val_size)), random_state=42)\n",
        "\n",
        "    def filter_by_video(video_list):\n",
        "        return [p for p in frames if os.path.dirname(p) in video_list]\n",
        "\n",
        "    return filter_by_video(train_videos), filter_by_video(val_videos), filter_by_video(test_videos)\n",
        "\n",
        "real_train, real_val, real_test = split_video_wise(real_sampled)\n",
        "fake_train, fake_val, fake_test = split_video_wise(fake_sampled)\n",
        "\n",
        "print(len(real_train), len(real_val), len(real_test))\n",
        "print(len(fake_train), len(fake_val), len(fake_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1JgIO1woQwR",
        "outputId": "d4d708c5-3346-4334-86e5-304b6b1646e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7000 1500 1500\n",
            "6988 1500 1500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    return running_loss / total, correct / total\n"
      ],
      "metadata": {
        "id": "WmsFe4bJU8GP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_one_epoch(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    return running_loss / total, correct / total\n"
      ],
      "metadata": {
        "id": "d6QYYjFbVApt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "def get_transforms(flip_p, brightness_p, noise_p, compression_p, dropout_p):\n",
        "    train_transforms = A.Compose([\n",
        "        A.Resize(224, 224),\n",
        "        A.HorizontalFlip(p=flip_p),\n",
        "        A.RandomBrightnessContrast(p=brightness_p),\n",
        "        A.GaussNoise(p=noise_p),\n",
        "        A.ImageCompression(quality_lower=30, quality_upper=100, p=compression_p),\n",
        "        A.CoarseDropout(\n",
        "            max_holes=1, max_height=30, max_width=30,\n",
        "            min_holes=1, min_height=10, min_width=10, p=dropout_p\n",
        "        ),\n",
        "        A.Normalize(mean=(0.485, 0.456, 0.406),\n",
        "                    std=(0.229, 0.224, 0.225)),\n",
        "        ToTensorV2()\n",
        "    ])\n",
        "\n",
        "    val_transforms = A.Compose([\n",
        "        A.Resize(224, 224),\n",
        "        A.Normalize(mean=(0.485, 0.456, 0.406),\n",
        "                    std=(0.229, 0.224, 0.225)),\n",
        "        ToTensorV2()\n",
        "    ])\n",
        "\n",
        "    return train_transforms, val_transforms\n"
      ],
      "metadata": {
        "id": "vl-wXYgLNM18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "\n",
        "def get_dataloaders(batch_size, train_transforms, val_transforms, real_train, fake_train, real_val, fake_val):\n",
        "    train_dataset = ConcatDataset([\n",
        "        DeepfakeDataset(real_train, 0, transform=train_transforms),\n",
        "        DeepfakeDataset(fake_train, 1, transform=train_transforms)\n",
        "    ])\n",
        "    val_dataset = ConcatDataset([\n",
        "        DeepfakeDataset(real_val, 0, transform=val_transforms),\n",
        "        DeepfakeDataset(fake_val, 1, transform=val_transforms)\n",
        "    ])\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    return train_loader, val_loader\n"
      ],
      "metadata": {
        "id": "cefBGoVrO8w5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(dropout_rate, num_classes=2, freeze_ratio=0.8):\n",
        "    # Load pretrained Xception model\n",
        "    model = timm.create_model('xception', pretrained=True)\n",
        "\n",
        "    # Freeze lower layers to reduce computation\n",
        "    num_layers = len(list(model.parameters()))\n",
        "    freeze_until = int(num_layers * freeze_ratio)\n",
        "\n",
        "    for i, param in enumerate(model.parameters()):\n",
        "        if i < freeze_until:\n",
        "            param.requires_grad = False\n",
        "\n",
        "    # Replace final classification head\n",
        "    in_features = model.fc.in_features\n",
        "    model.fc = nn.Sequential(\n",
        "        nn.Linear(in_features, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(dropout_rate),\n",
        "        nn.Linear(512, num_classes)\n",
        "    )\n",
        "\n",
        "    # Move model to appropriate device (GPU/CPU)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    return model, device"
      ],
      "metadata": {
        "id": "cT_0a3JuszD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    # --- Hyperparameter suggestions ---\n",
        "    lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-3)\n",
        "    weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-6, 1e-3)\n",
        "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.3, 0.6)\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64])\n",
        "    flip_p = trial.suggest_float(\"flip_p\", 0.3, 0.8)\n",
        "    brightness_p = trial.suggest_float(\"brightness_p\", 0.2, 0.6)\n",
        "    noise_p = trial.suggest_float(\"noise_p\", 0.1, 0.4)\n",
        "    compression_p = trial.suggest_float(\"compression_p\", 0.2, 0.5)\n",
        "    dropout_p = trial.suggest_float(\"dropout_p\", 0.1, 0.4)\n",
        "\n",
        "    # --- Build everything using helper functions ---\n",
        "    train_transforms, val_transforms = get_transforms(flip_p, brightness_p, noise_p, compression_p, dropout_p)\n",
        "    train_loader, val_loader = get_dataloaders(batch_size, train_transforms, val_transforms, real_train, fake_train, real_val, fake_val)\n",
        "    model, device = get_model(dropout_rate)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2, factor=0.5)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    best_val_acc = 0.0\n",
        "    num_epochs = 3\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\nüöÄ Epoch [{epoch+1}/{num_epochs}] (Trial {trial.number + 1})\")\n",
        "        train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
        "        val_loss, val_acc = validate_one_epoch(model, val_loader, criterion, device)\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
        "        print(f\"Val Loss:   {val_loss:.4f}, Val Acc:   {val_acc:.4f}\")\n",
        "\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "\n",
        "    return best_val_acc\n"
      ],
      "metadata": {
        "id": "zJgkv8a1WBIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAf3Z0U_ZRoz",
        "outputId": "e1186d25-cddb-4a03-cdb0-7fe698a66fdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.5.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.17.0)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.44)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n",
            "Downloading optuna-4.5.0-py3-none-any.whl (400 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, optuna\n",
            "Successfully installed colorlog-6.10.1 optuna-4.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "# ===========================\n",
        "# RUN OPTUNA STUDY\n",
        "# ===========================\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=10)\n",
        "\n",
        "print(\"Best hyperparameters:\")\n",
        "print(study.best_params)\n",
        "print(\"Best validation accuracy:\")\n",
        "print(study.best_value)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7_pmrgZZHv8",
        "outputId": "4a05f356-8863-46c8-e492-07a297495d5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-10-18 17:26:17,050] A new study created in memory with name: no-name-7418c4da-6d46-4e97-8c1a-f900f3ac8cc4\n",
            "/tmp/ipython-input-1049881781.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-3)\n",
            "/tmp/ipython-input-1049881781.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-6, 1e-3)\n",
            "/tmp/ipython-input-765546707.py:10: UserWarning: Argument(s) 'quality_lower, quality_upper' are not valid for transform ImageCompression\n",
            "  A.ImageCompression(quality_lower=30, quality_upper=100, p=compression_p),\n",
            "/tmp/ipython-input-765546707.py:11: UserWarning: Argument(s) 'max_holes, max_height, max_width, min_holes, min_height, min_width' are not valid for transform CoarseDropout\n",
            "  A.CoarseDropout(\n",
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name xception to current legacy_xception.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-cadene/xception-43020ad28.pth\" to /root/.cache/torch/hub/checkpoints/xception-43020ad28.pth\n",
            "\n",
            "üöÄ Epoch [1/3] (Trial 1)\n",
            "Train Loss: 0.4720, Train Acc: 0.7446\n",
            "Val Loss:   0.2387, Val Acc:   0.8943\n",
            "\n",
            "üöÄ Epoch [2/3] (Trial 1)\n",
            "Train Loss: 0.2579, Train Acc: 0.8829\n",
            "Val Loss:   0.2229, Val Acc:   0.9040\n",
            "\n",
            "üöÄ Epoch [3/3] (Trial 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-10-18 18:26:08,089] Trial 0 finished with value: 0.9073333333333333 and parameters: {'lr': 1.0347111436502708e-05, 'weight_decay': 1.9053836607902433e-05, 'dropout_rate': 0.3215435255636158, 'batch_size': 16, 'flip_p': 0.7149653104858829, 'brightness_p': 0.36913895775030114, 'noise_p': 0.33107810776432345, 'compression_p': 0.29388511875788154, 'dropout_p': 0.2459611101547788}. Best is trial 0 with value: 0.9073333333333333.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1882, Train Acc: 0.9159\n",
            "Val Loss:   0.2185, Val Acc:   0.9073\n",
            "\n",
            "üöÄ Epoch [1/3] (Trial 2)\n",
            "Train Loss: 0.2240, Train Acc: 0.8925\n",
            "Val Loss:   0.2807, Val Acc:   0.9167\n",
            "\n",
            "üöÄ Epoch [2/3] (Trial 2)\n",
            "Train Loss: 0.1071, Train Acc: 0.9540\n",
            "Val Loss:   0.5169, Val Acc:   0.8840\n",
            "\n",
            "üöÄ Epoch [3/3] (Trial 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-10-18 18:38:48,535] Trial 1 finished with value: 0.9166666666666666 and parameters: {'lr': 0.0003923245096601874, 'weight_decay': 1.7578179016206945e-05, 'dropout_rate': 0.49826107453660406, 'batch_size': 64, 'flip_p': 0.45804404511299446, 'brightness_p': 0.5798043459818183, 'noise_p': 0.35152770705903036, 'compression_p': 0.3109706119792101, 'dropout_p': 0.3275152809651438}. Best is trial 1 with value: 0.9166666666666666.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0757, Train Acc: 0.9686\n",
            "Val Loss:   0.4814, Val Acc:   0.9020\n",
            "\n",
            "üöÄ Epoch [1/3] (Trial 3)\n",
            "Train Loss: 0.3789, Train Acc: 0.8074\n",
            "Val Loss:   0.2790, Val Acc:   0.8843\n",
            "\n",
            "üöÄ Epoch [2/3] (Trial 3)\n",
            "Train Loss: 0.1606, Train Acc: 0.9260\n",
            "Val Loss:   0.2573, Val Acc:   0.8993\n",
            "\n",
            "üöÄ Epoch [3/3] (Trial 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-10-18 18:51:18,302] Trial 2 finished with value: 0.8993333333333333 and parameters: {'lr': 2.1272702870191657e-05, 'weight_decay': 6.627907076486246e-05, 'dropout_rate': 0.5619623772323921, 'batch_size': 32, 'flip_p': 0.597310531882963, 'brightness_p': 0.27312962957546305, 'noise_p': 0.22903612808350177, 'compression_p': 0.4162528085839039, 'dropout_p': 0.16530908969848232}. Best is trial 1 with value: 0.9166666666666666.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1110, Train Acc: 0.9492\n",
            "Val Loss:   0.2464, Val Acc:   0.8990\n",
            "\n",
            "üöÄ Epoch [1/3] (Trial 4)\n",
            "Train Loss: 0.3441, Train Acc: 0.8368\n",
            "Val Loss:   0.1931, Val Acc:   0.9163\n",
            "\n",
            "üöÄ Epoch [2/3] (Trial 4)\n",
            "Train Loss: 0.1282, Train Acc: 0.9435\n",
            "Val Loss:   0.2007, Val Acc:   0.9080\n",
            "\n",
            "üöÄ Epoch [3/3] (Trial 4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-10-18 19:03:18,229] Trial 3 finished with value: 0.9163333333333333 and parameters: {'lr': 1.3502556845070965e-05, 'weight_decay': 2.2483725045333006e-06, 'dropout_rate': 0.3137856481470619, 'batch_size': 16, 'flip_p': 0.7139841321340217, 'brightness_p': 0.41118075798825693, 'noise_p': 0.10551501119570122, 'compression_p': 0.36962611387988004, 'dropout_p': 0.3522229774273471}. Best is trial 1 with value: 0.9166666666666666.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0904, Train Acc: 0.9608\n",
            "Val Loss:   0.2227, Val Acc:   0.9093\n",
            "\n",
            "üöÄ Epoch [1/3] (Trial 5)\n",
            "Train Loss: 0.3125, Train Acc: 0.8460\n",
            "Val Loss:   0.2276, Val Acc:   0.8990\n",
            "\n",
            "üöÄ Epoch [2/3] (Trial 5)\n",
            "Train Loss: 0.1126, Train Acc: 0.9468\n",
            "Val Loss:   0.2116, Val Acc:   0.9187\n",
            "\n",
            "üöÄ Epoch [3/3] (Trial 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-10-18 19:15:57,054] Trial 4 finished with value: 0.9186666666666666 and parameters: {'lr': 3.5264245602654906e-05, 'weight_decay': 3.360243846464907e-06, 'dropout_rate': 0.4190259099974515, 'batch_size': 64, 'flip_p': 0.4443220982140699, 'brightness_p': 0.2769184472389101, 'noise_p': 0.1542661711451799, 'compression_p': 0.33001902072735567, 'dropout_p': 0.23258255380879642}. Best is trial 4 with value: 0.9186666666666666.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0796, Train Acc: 0.9645\n",
            "Val Loss:   0.2527, Val Acc:   0.9093\n",
            "\n",
            "üöÄ Epoch [1/3] (Trial 6)\n",
            "Train Loss: 0.2260, Train Acc: 0.8911\n",
            "Val Loss:   0.1987, Val Acc:   0.9227\n",
            "\n",
            "üöÄ Epoch [2/3] (Trial 6)\n",
            "Train Loss: 0.1100, Train Acc: 0.9542\n",
            "Val Loss:   0.2685, Val Acc:   0.9017\n",
            "\n",
            "üöÄ Epoch [3/3] (Trial 6)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-10-18 19:27:58,601] Trial 5 finished with value: 0.9226666666666666 and parameters: {'lr': 6.784292459046897e-05, 'weight_decay': 0.00013858849651110877, 'dropout_rate': 0.313977730486625, 'batch_size': 16, 'flip_p': 0.6464796243208715, 'brightness_p': 0.4652172584114009, 'noise_p': 0.2542681263548501, 'compression_p': 0.400378458078973, 'dropout_p': 0.1912157613506834}. Best is trial 5 with value: 0.9226666666666666.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0752, Train Acc: 0.9706\n",
            "Val Loss:   0.2515, Val Acc:   0.9153\n",
            "\n",
            "üöÄ Epoch [1/3] (Trial 7)\n",
            "Train Loss: 0.3979, Train Acc: 0.7970\n",
            "Val Loss:   0.2459, Val Acc:   0.8937\n",
            "\n",
            "üöÄ Epoch [2/3] (Trial 7)\n",
            "Train Loss: 0.1937, Train Acc: 0.9161\n",
            "Val Loss:   0.3370, Val Acc:   0.8617\n",
            "\n",
            "üöÄ Epoch [3/3] (Trial 7)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-10-18 19:40:00,144] Trial 6 finished with value: 0.902 and parameters: {'lr': 2.022002750531822e-05, 'weight_decay': 3.3268652982950237e-06, 'dropout_rate': 0.44505542127756087, 'batch_size': 16, 'flip_p': 0.5948280971161483, 'brightness_p': 0.23190670606321717, 'noise_p': 0.3732130527420592, 'compression_p': 0.3889292719510371, 'dropout_p': 0.3691637849814019}. Best is trial 5 with value: 0.9226666666666666.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1485, Train Acc: 0.9348\n",
            "Val Loss:   0.2726, Val Acc:   0.9020\n",
            "\n",
            "üöÄ Epoch [1/3] (Trial 8)\n",
            "Train Loss: 0.2387, Train Acc: 0.8840\n",
            "Val Loss:   0.2477, Val Acc:   0.8887\n",
            "\n",
            "üöÄ Epoch [2/3] (Trial 8)\n",
            "Train Loss: 0.0969, Train Acc: 0.9555\n",
            "Val Loss:   0.2011, Val Acc:   0.9180\n",
            "\n",
            "üöÄ Epoch [3/3] (Trial 8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-10-18 19:52:02,483] Trial 7 finished with value: 0.921 and parameters: {'lr': 3.2823549601535595e-05, 'weight_decay': 0.00038999079732882807, 'dropout_rate': 0.30822175682122444, 'batch_size': 16, 'flip_p': 0.4224689710403889, 'brightness_p': 0.2343596684583793, 'noise_p': 0.1436892929559281, 'compression_p': 0.3485502567594729, 'dropout_p': 0.22172633921860507}. Best is trial 5 with value: 0.9226666666666666.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0742, Train Acc: 0.9672\n",
            "Val Loss:   0.2249, Val Acc:   0.9210\n",
            "\n",
            "üöÄ Epoch [1/3] (Trial 9)\n",
            "Train Loss: 0.2527, Train Acc: 0.8794\n",
            "Val Loss:   0.2792, Val Acc:   0.8923\n",
            "\n",
            "üöÄ Epoch [2/3] (Trial 9)\n",
            "Train Loss: 0.1154, Train Acc: 0.9515\n",
            "Val Loss:   0.4960, Val Acc:   0.8700\n",
            "\n",
            "üöÄ Epoch [3/3] (Trial 9)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-10-18 20:04:03,583] Trial 8 finished with value: 0.9073333333333333 and parameters: {'lr': 5.7816923559252956e-05, 'weight_decay': 3.896572747075895e-06, 'dropout_rate': 0.3214158733807664, 'batch_size': 16, 'flip_p': 0.32592136411531586, 'brightness_p': 0.5770552770112205, 'noise_p': 0.2612249019073033, 'compression_p': 0.4263864644169515, 'dropout_p': 0.2833366920808057}. Best is trial 5 with value: 0.9226666666666666.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0892, Train Acc: 0.9623\n",
            "Val Loss:   0.2667, Val Acc:   0.9073\n",
            "\n",
            "üöÄ Epoch [1/3] (Trial 10)\n",
            "Train Loss: 0.5212, Train Acc: 0.7420\n",
            "Val Loss:   0.3262, Val Acc:   0.8687\n",
            "\n",
            "üöÄ Epoch [2/3] (Trial 10)\n",
            "Train Loss: 0.2485, Train Acc: 0.8951\n",
            "Val Loss:   0.2405, Val Acc:   0.8987\n",
            "\n",
            "üöÄ Epoch [3/3] (Trial 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-10-18 20:16:43,599] Trial 9 finished with value: 0.9053333333333333 and parameters: {'lr': 1.0454531008720144e-05, 'weight_decay': 3.653306260836255e-05, 'dropout_rate': 0.5753045502840166, 'batch_size': 64, 'flip_p': 0.7833194321625924, 'brightness_p': 0.25907842444548945, 'noise_p': 0.17685650253488194, 'compression_p': 0.3546127115115837, 'dropout_p': 0.12892138920468682}. Best is trial 5 with value: 0.9226666666666666.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1567, Train Acc: 0.9349\n",
            "Val Loss:   0.2305, Val Acc:   0.9053\n",
            "Best hyperparameters:\n",
            "{'lr': 6.784292459046897e-05, 'weight_decay': 0.00013858849651110877, 'dropout_rate': 0.313977730486625, 'batch_size': 16, 'flip_p': 0.6464796243208715, 'brightness_p': 0.4652172584114009, 'noise_p': 0.2542681263548501, 'compression_p': 0.400378458078973, 'dropout_p': 0.1912157613506834}\n",
            "Best validation accuracy:\n",
            "0.9226666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "save_path = \"/content/drive/MyDrive/processed_faces_final/best_params.json\"  # you can change the folder name\n",
        "with open(save_path, \"w\") as f:\n",
        "    json.dump(study.best_params, f, indent=4)\n",
        "\n",
        "print(f\"‚úÖ Best parameters saved to: {save_path}\")\n"
      ],
      "metadata": {
        "id": "bHH62BmFWIgT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbb9e9a9-2c8f-4317-9ff0-581f3ea39e12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Best parameters saved to: /content/drive/MyDrive/processed_faces_final/best_params.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Path where you saved the file\n",
        "load_path = \"/content/drive/MyDrive/processed_faces_final/best_params.json\"\n",
        "\n",
        "# Load parameters from JSON\n",
        "with open(load_path, \"r\") as f:\n",
        "    best_params = json.load(f)\n",
        "\n",
        "print(\"Loaded best hyperparameters:\", best_params)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FO8JlWwaoRAi",
        "outputId": "d15db0fc-c508-46b2-d581-b5782f909c26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded best hyperparameters: {'lr': 6.784292459046897e-05, 'weight_decay': 0.00013858849651110877, 'dropout_rate': 0.313977730486625, 'batch_size': 16, 'flip_p': 0.6464796243208715, 'brightness_p': 0.4652172584114009, 'noise_p': 0.2542681263548501, 'compression_p': 0.400378458078973, 'dropout_p': 0.1912157613506834}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(num_classes=2, freeze_ratio=0.8):\n",
        "    # Load pretrained model\n",
        "    model = timm.create_model('xception', pretrained=True)\n",
        "\n",
        "    # Freeze lower layers\n",
        "    num_layers = len(list(model.parameters()))\n",
        "    freeze_until = int(num_layers * freeze_ratio)\n",
        "\n",
        "    for i, param in enumerate(model.parameters()):\n",
        "        if i < freeze_until:\n",
        "            param.requires_grad = False\n",
        "\n",
        "    # Replace final classification head\n",
        "    in_features = model.fc.in_features\n",
        "    model.fc = nn.Sequential(\n",
        "        nn.Linear(in_features, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.3),\n",
        "        nn.Linear(512, num_classes)\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "A4JcVbNWq8O-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ===========================\n",
        "# TRAIN FINAL MODEL WITH BEST PARAMS\n",
        "# ===========================\n",
        "\n",
        "# Reuse the same helper functions for final training\n",
        "train_transforms, val_transforms = get_transforms(\n",
        "    best_params[\"flip_p\"],\n",
        "    best_params[\"brightness_p\"],\n",
        "    best_params[\"noise_p\"],\n",
        "    best_params[\"compression_p\"],\n",
        "    best_params[\"dropout_p\"]\n",
        ")\n",
        "\n",
        "train_loader, val_loader = get_dataloaders(\n",
        "    best_params[\"batch_size\"],\n",
        "    train_transforms,\n",
        "    val_transforms,\n",
        "    real_train, fake_train, real_val, fake_val\n",
        ")\n",
        "\n",
        "model, device = get_model(best_params[\"dropout_rate\"])\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=best_params[\"lr\"], weight_decay=best_params[\"weight_decay\"])\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2, factor=0.5)\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
        "    val_loss, val_acc = validate_one_epoch(model, val_loader, criterion, device)\n",
        "    scheduler.step(val_loss)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "hWXaNy7LaHAs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b8d574c-b8ea-4092-f564-fb659b3b7c49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-765546707.py:10: UserWarning: Argument(s) 'quality_lower, quality_upper' are not valid for transform ImageCompression\n",
            "  A.ImageCompression(quality_lower=30, quality_upper=100, p=compression_p),\n",
            "/tmp/ipython-input-765546707.py:11: UserWarning: Argument(s) 'max_holes, max_height, max_width, min_holes, min_height, min_width' are not valid for transform CoarseDropout\n",
            "  A.CoarseDropout(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10] - Train Acc: 0.8477, Val Acc: 0.8767\n",
            "Epoch [2/10] - Train Acc: 0.9136, Val Acc: 0.8920\n",
            "Epoch [3/10] - Train Acc: 0.9272, Val Acc: 0.8870\n",
            "Epoch [4/10] - Train Acc: 0.9353, Val Acc: 0.8693\n",
            "Epoch [5/10] - Train Acc: 0.9429, Val Acc: 0.8827\n",
            "Epoch [6/10] - Train Acc: 0.9514, Val Acc: 0.8920\n",
            "Epoch [7/10] - Train Acc: 0.9514, Val Acc: 0.8873\n",
            "Epoch [8/10] - Train Acc: 0.9530, Val Acc: 0.8723\n",
            "Epoch [9/10] - Train Acc: 0.9579, Val Acc: 0.8947\n",
            "Epoch [10/10] - Train Acc: 0.9586, Val Acc: 0.8957\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "save_path = \"/content/drive/MyDrive/processed_faces_final/best_xception_optuna.pth\"\n",
        "torch.save(model.state_dict(), save_path)\n",
        "\n",
        "print(f\"‚úÖ Model saved to: {save_path}\")\n"
      ],
      "metadata": {
        "id": "nRykvRZQRm2M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d34f9f63-d277-493c-8304-560c0f9c6ddb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Model saved to: /content/drive/MyDrive/processed_faces_final/best_xception_optuna.pth\n"
          ]
        }
      ]
    }
  ]
}